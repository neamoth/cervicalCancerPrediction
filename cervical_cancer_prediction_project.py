# -*- coding: utf-8 -*-
"""Cervical_Cancer_prediction_project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/github/mamun-cse-diu/cervical_Cancer_Prediction/blob/main/Cervical_Cancer_prediction_project.ipynb
"""

import pandas as pd
import seaborn as sns
import numpy as np
import matplotlib.pyplot as plt

"""Importing data from train data set"""

url = "https://raw.githubusercontent.com/mamun-cse-diu/cervical_Cancer_Prediction/main/train.csv"
data = pd.read_csv(url)
data.info()

data.tail(20)

data.info()

data.describe()

"""REPLACING '?' WITH NaN"""

data = data.replace('?', np.nan)
data

"""PLOTTING HEATMAP TO VISUALIZE THE NUMBER OF NaN'S IN TH DATA"""

plt.figure(figsize=(20,20))
sns.heatmap(data.isnull(), yticklabels = False)
plt.show()

"""WE OBSERVE THAT THERE ARE A LOT OF NAN VALUES IN "STD'S: TIME SINCE FIRST DIAGNOSIS" AND "STD'S: TIME SINCE LAST DIAGNOSIS" 
SO WE WILL DROP THESE COLUMNS
"""

data = data.drop(['STDs: Time since first diagnosis', 'STDs: Time since last diagnosis'], axis=1)
data

"""Converting the column data types, from object to numeric in order to perform Statistical Analysis of the Data

"""

data = data.apply(pd.to_numeric)
data.info()

data.describe()

data.mean()

"""# REPLACING NULL/NaN values with the mean values:"""

data =  data.fillna(data.mean())
data

"""# PLOTTING HEATMAP AGAIN TO VISUALIZE AND CHECK OUR DATA CLEANSING"""

plt.figure(figsize=(8,20))
sns.heatmap(data.isnull(), yticklabels = False)
plt.xticks(rotation=90)
plt.tick_params(labelsize=8)
plt.show()

data.describe()

"""# WE'LL TRY TO OBSERVE THE CORELATION BETWEEN DIFFERENT FEATURES IN OUR DATASETS:"""

corr_matrix = data.corr()

corr_matrix

"""# PLOTTING THE HEATMAP FOR CORRELATION MATRIX"""

plt.figure(figsize = (30,30))
sns.heatmap(corr_matrix, annot=True)
plt.xticks(rotation=90)
plt.yticks(rotation=360)
plt.tick_params(labelsize=8)
plt.show()

"""# VISUALIZING THE WHOLE DATAFRAME BY PLOTTING HISTOGRAM"""

data.hist(bins = 10, figsize = (30,30), color='blue')
plt.show()

"""# WE SELECT BIOPSY DATA AS OUR TARGET VALUES:"""

target_df = data['Biopsy']
input_df = data.drop(['Biopsy'], axis=1)

x = input_df 
y = target_df

x

"""# Recursive Feature Elimination"""

from pandas import read_csv
from sklearn.feature_selection import RFE
from sklearn.linear_model import LogisticRegression

model = LogisticRegression(solver='lbfgs')
n_features_to_select = 20
rfe = RFE(model, n_features_to_select=n_features_to_select)

fit = rfe.fit(x, y)
print("Num Features: %d" % fit.n_features_)
print("Selected Features: %s" % fit.support_)
print("Feature Ranking: %s" % fit.ranking_)

list(zip(x.columns,rfe.support_,rfe.ranking_))

cols = x.columns[rfe.support_]
cols

X1 = x[cols]
X1

"""# Univariate Selection"""

import numpy as np
from sklearn.feature_selection import SelectKBest
from sklearn.feature_selection import chi2
from sklearn.feature_selection import SelectPercentile, f_classif
np.seterr(divide='ignore', invalid='ignore');
selector=SelectPercentile(f_classif, percentile=80)
X_newDoS = selector.fit_transform(X1,y)
X_newDoS.shape

colNames = list(X1)

true=selector.get_support()
newcolindex_DoS=[i for i, a in enumerate(true) if a]
newcolname_DoS=list( colNames[i] for i in newcolindex_DoS )
newcolname_DoS

X_newProbe = selector.fit_transform(X1,y)
X_newProbe.shape

"""# Now X2 is main data set"""

X2_train = x[newcolname_DoS]
X2_train

"""# Split data set"""

from sklearn.model_selection import train_test_split
from sklearn import metrics
import matplotlib.pyplot as mtp
x_train,x_test,y_train,y_test= train_test_split(X2_train,y,test_size=0.2, random_state=42)

x_train

y_train

x_test

from sklearn.svm import SVC
from sklearn import metrics
from sklearn.metrics import classification_report , confusion_matrix

"""# Implementation of Support Vector Machine"""

sm=SVC(probability=True)
sm.fit(x_train,y_train)
y_pred_sm=sm.predict(x_test)

"""# Implementation of Random Forest"""

from sklearn.ensemble import RandomForestClassifier
RF=RandomForestClassifier(n_estimators=100)
RF.fit(x_train,y_train)
y_pred_RF=RF.predict(x_test)

"""# Implementation of Knn"""

from sklearn.neighbors import KNeighborsClassifier

KN = KNeighborsClassifier()

KN.fit(x_train, y_train)
KN_predict = KN.predict(x_test)

"""# Compare 3 model"""

print("Train dataset Accuracy of SVM: ",metrics.accuracy_score(y_test,y_pred_sm)*100)
print("Train dataset Accuracy of RF: ",metrics.accuracy_score(y_test,y_pred_RF)*100)
print("Train dataset Accuracy of Knn: ",metrics.accuracy_score(y_test,KN_predict)*100)

"""# Now work with test dataset"""

url = "https://raw.githubusercontent.com/mamun-cse-diu/cervical_Cancer_Prediction/main/test_data.csv"
data_test = pd.read_csv(url)
data_test.info()

data_test.tail(20)

data_test.describe()

data_test.hist(bins = 10, figsize = (30,30), color='blue')
plt.show()

"""WE SELECT BIOPSY DATA AS OUR TARGET VALUES:"""

yTest = data_test['Biopsy']
xTest = data_test.drop(['Biopsy'], axis=1)

xTest

"""Recursive Feature Elimination using test dataset"""

from pandas import read_csv
from sklearn.feature_selection import RFE
from sklearn.linear_model import LogisticRegression

model = LogisticRegression(solver='lbfgs')
n_features_to_select = 20
rfe = RFE(model, n_features_to_select=n_features_to_select)

fit = rfe.fit(xTest, yTest)
print("Num Features: %d" % fit.n_features_)
print("Selected Features: %s" % fit.support_)
print("Feature Ranking: %s" % fit.ranking_)

list(zip(xTest.columns,rfe.support_,rfe.ranking_))

cols_of_xTest = xTest.columns[rfe.support_]
cols_of_xTest

X1_test = xTest[cols_of_xTest]
X1_test

colNames_test=list(X1_test)

"""Univariate Selection for test dataset"""

import numpy as np
from sklearn.feature_selection import SelectPercentile, f_classif
np.seterr(divide='ignore', invalid='ignore');
selector_test=SelectPercentile(f_classif, percentile=80)
X_newDoS_test = selector_test.fit_transform(X1_test,yTest)
X_newDoS_test.shape

true=selector_test.get_support()
newcolindex_DoS_test=[i for i, b in enumerate(true) if b]
newcolname_DoS_test=list( colNames_test[i] for i in newcolindex_DoS_test )
newcolname_DoS_test

X_newProbe_test = selector_test.fit_transform(X1_test,yTest)
X_newProbe_test.shape

X2_test = xTest[newcolname_DoS_test]
X2_test

"""Split data set"""

from sklearn.model_selection import train_test_split
from sklearn import metrics
import matplotlib.pyplot as mtp
xx_train,xx_test,yy_train,yy_test= train_test_split(X2_test,yTest,test_size=0.2, random_state=42)

xx_train

yy_train

xx_test

from sklearn.svm import SVC
from sklearn import metrics
from sklearn.metrics import classification_report , confusion_matrix

"""Implementation of Support Vector Machine for test dataset"""

sm_test=SVC(probability=True)
sm_test.fit(xx_train,yy_train)
y_pred_sm_test=sm_test.predict(xx_test)

"""Implementation of Random Forest for test data"""

from sklearn.ensemble import RandomForestClassifier
RF_test=RandomForestClassifier(n_estimators=100)
RF_test.fit(xx_train,yy_train)
y_pred_RF_test=RF_test.predict(xx_test)

"""Implementation of Knn for test dataset"""

from sklearn.neighbors import KNeighborsClassifier

KN_test = KNeighborsClassifier()

KN_test.fit(xx_train, yy_train)
KN_predict_test = KN_test.predict(xx_test)

"""Compare 3 model for test dataset"""

print("Train dataset Accuracy of SVM: ",metrics.accuracy_score(y_test,y_pred_sm)*100)
print("Train dataset Accuracy of RF: ",metrics.accuracy_score(y_test,y_pred_RF)*100)
print("Train dataset Accuracy of Knn: ",metrics.accuracy_score(y_test,KN_predict)*100)

print("\n\n\n\nTest dataset Accuracy of SVM: ",metrics.accuracy_score(yy_test,y_pred_sm_test)*100)
print("Test dataset Accuracy of RF: ",metrics.accuracy_score(yy_test,y_pred_RF_test)*100)
print("Test dataset Accuracy of Knn: ",metrics.accuracy_score(yy_test,KN_predict_test)*100)